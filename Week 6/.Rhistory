return_ts = ts(return, start = 2007+(10/12), end = 2012 + (7/12), freq = 252)
plot(ApplPrice_ts, type = "l", main = "Plot of Apple Price", xlab = "Year", ylab = "Price")
plot(return_ts, type = "l", main = "Plot of Apple return", xlab = "Year", ylab = "Return")
acf(ApplPrice_ts, main = "ACF of Apple Price", type = "correlation")
pacf(ApplPrice_ts, main = "pACF of Apple Price")
acf(return_ts, main = "ACF of Apple return")
pacf(return_ts, main = "PACF of Apple return")
ar1 = Arima(ApplPrice_ts, order = c(1,1,0))
acf(ar1$residuals, main = "ACF of the residuals")
pacf(ar1$residuals, main = "PACF of the residuals")
Box.test(ar1$residuals)
ar1.pred = forecast(ar1, h = 10)
print("The point forecast for the 10-step ahead is as follows:")
print(ar1.pred$mean)
print(paste("While the value at the last observation is", toString(ar1$fitted[length(ar1$fitted)])))
rm(list = ls(all=TRUE))
data = read.csv("7.2.csv")
names(data) = c('date', 'unemploy_thousands')
attach(data)
unemploy_thousands_ts = ts(unemploy_thousands, start = 1989, freq = 12)
plot(unemploy_thousands_ts, main = "Plot of unemployed in thousands")
unemploy_thousands_ts = ts(unemploy_thousands, start = 1989, frequency = 12)
acf(unemploy_thousands_ts, main = "ACF of number of unemployed in thousands")
pacf(unemploy_thousands_ts, main = "PACF of number of unemployed in thousands")
acf(unemploy_thousands_ts[1:100], main = "ACF of number of unemployed in thousands")
pacf(unemploy_thousands_ts[1:100], main = "PACF of number of unemployed in thousands")
acf(unemploy_thousands_ts[2:200], main = "ACF of number of unemployed in thousands")
pacf(unemploy_thousands_ts[2:200], main = "PACF of number of unemployed in thousands")
acf(unemploy_thousands_ts[183:283], main = "ACF of number of unemployed in thousands")
pacf(unemploy_thousands_ts[183:283], main = "PACF of number of unemployed in thousands")
rm(list = ls(all=TRUE))
data = read.csv("7.6.csv")
names(data)[c(3,5)] = c("housing.inflation", "transportation.inflation")
attach(data)
hinf_ts = ts(housing.inflation, start = 1976, freq = 1)
tinf_ts = ts(transportation.inflation, start = 1976, freq = 1)
acf(hinf_ts[complete.cases(hinf_ts)], main = "ACF of housing inflation")
pacf(hinf_ts[complete.cases(hinf_ts)],  main = "PACF of housing inflation")
acf(tinf_ts[complete.cases(tinf_ts)], main = "ACF of the transportation inflation")
pacf(tinf_ts[complete.cases(tinf_ts)],  main = "PACF of the transportation inflation")
rm(list = ls(all=TRUE))
data = read.csv("7.7.csv")
names(data)[c(3,5)] = c("food.inflation", "Gas.inflation")
attach(data)
finf_ts = ts(food.inflation, start = 1957, freq = 1)
finf_ts = finf_ts [complete.cases(finf_ts )]
ginf_ts = ts(Gas.inflation, start = 1957, freq = 1)
ginf_ts = ginf_ts [complete.cases(ginf_ts)]
acf(finf_ts, main = "ACF of the food inflation")
pacf(finf_ts, main = "PACF of the food inflation")
acf(ginf_ts, main = "ACF of the Gas inflation")
pacf(ginf_ts, main = "PACF of the Gas inflation")
new_ginf_ts = rollmean(ginf_ts, 3)
acf(new_ginf_ts)
pacf(new_ginf_ts)
finf_ar3 = Arima(finf_ts, order = c(3,0,0), method = "ML")
ginf_ar2 = Arima(new_ginf_ts, order = c(2,0,0), method = "ML")
acf(finf_ar3$residuals[complete.cases(finf_ar3$residuals)])
pacf(finf_ar3$residuals[complete.cases(finf_ar3$residuals)])
acf(ginf_ar2 $residuals[complete.cases(ginf_ar2$residuals)])
pacf(ginf_ar2 $residuals[complete.cases(ginf_ar2$residuals)])
#last element index
ind = length(food.CPI)
#last element for the CPIs and the inflations
lastelfInf = food.inflation[ind]
lastelgInf = Gas.inflation[ind]
#for food inflation, create a list of realized future values
e = rnorm(3)
finf = vector()
finf[1] = food.inflation[length(food.inflation)-2]
finf[2] = food.inflation[length(food.inflation)-1]
finf[3] = food.inflation[length(food.inflation)]
finf[4] = finf_ar3$coef[4] + finf_ar3$coef[1]*finf[3] + finf_ar3$coef[2]*finf[2] +finf_ar3$coef[3]*finf[1] + e[1]
finf[5] = finf_ar3$coef[4] + finf_ar3$coef[1]*finf[4] + finf_ar3$coef[2]*finf[3] +finf_ar3$coef[3]*finf[2] + e[2]
finf[6] = finf_ar3$coef[4] + finf_ar3$coef[1]*finf[5] + finf_ar3$coef[2]*finf[4] +finf_ar3$coef[3]*finf[3] + e[3]
finf_ar3.pred = forecast(finf_ar3,h=3)
print("For food inflation AR(3,0),")
for (i in 1:3){
print(paste("Point forecast for", toString(i), "step(s) is", toString(finf_ar3.pred$mean[i])))
print(paste("Forecast error for", toString(i), "step(s) is", toString(finf[3+i] -finf_ar3.pred$mean[i])))
#Since the upper bound of 95% confidence interval = point_forecast + 1.96(forecast_variance)
forecast_variance = (finf_ar3.pred$upper[i,2] - finf_ar3.pred$mean[i])/1.96
print(paste("Forecast uncertainty for", toString(i), "step(s) is", toString(forecast_variance)))
cat("\n")
}
#do similarly as the above
ginf = vector()
ginf[1] = Gas.inflation[length(Gas.inflation)-1]
ginf[2] = Gas.inflation[length(Gas.inflation)]
ginf[3] = ginf_ar2$coef[3] + ginf_ar2$coef[1]*ginf[2] + ginf_ar2$coef[2]*ginf[1] + e[1]
ginf[4] = ginf_ar2$coef[3] + ginf_ar2$coef[1]*ginf[3] + ginf_ar2$coef[2]*ginf[2] + e[2]
ginf[5] = ginf_ar2$coef[3] + ginf_ar2$coef[1]*ginf[4] + ginf_ar2$coef[2]*ginf[3]+ e[3]
ginf_ar2.pred = forecast(ginf_ar2,h=3)
print("For gas inflation AR(1,0),")
for (i in 1:3){
print(paste("Point forecast for", toString(i), "step(s) is", toString(ginf_ar2.pred$mean[i])))
print(paste("Forecast error for", toString(i), "step(s) is", toString(ginf[2+i] -ginf_ar2.pred$mean[i])))
#Since the upper bound of 95% confidence interval = point_forecast + 1.96(forecast_variance)
forecast_variance = (ginf_ar2.pred$upper[i,2] - ginf_ar2.pred$mean[i])/1.96
print(paste("Forecast uncertainty for", toString(i), "step(s) is", toString(forecast_variance)))
cat("\n")
}
help(recresid)
??recresid
brary(TTR)
library(fpp)
library(strucchange)
install.packages("strucchange")
help(ts.union)
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 05/10/2015A
# Comment(s): R code for fitting VAR models
# Data File(s): housecomp.dat
#***********************************************
# Variable Definitions
# U.S. monthly seasonally adjusred housing starts and completion
# from 1968.01-1996.06
# housecomp.dat[,2] = housing starts
# housecomp.dat[,3] = hoising completion
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Lenovo/Desktop/Econ 144/Week 6")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library(TTR)
library(tis)
require("datasets")
require(graphics)
library(forecast)
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
library(strucchange)
#library(MSBVAR)
library(vars)
library(lmtest)
library(dlnm)
# Look at the data
data=read.table("housecomp.dat")
starts<-ts(data[,2],start=1968.1,freq=12)
comps<-ts(data[,3],start=1968.1,freq=12)
windows()
plot(starts)
nberShade()
lines(starts,ylab="Housing Starts and Completions")
lines(comps,col="blue")
legend("topright",legend=c("Starts","Completions"),text.col=c("black","blue"),bty="n")
# Look at the ACF, PACF, and CCF (cros-correlation function)
windows()
tsdisplay(starts,main="Housing Starts")
windows()
tsdisplay(comps,main="Housing Completions")
windows()
ccf(starts,comps,ylab="Cross-Correlation Function", main = "Starts and Completions CCF")
# Completions are maximally correlated with starts lagged by 6-12 months.
# Fit a VAR(p) model to the data
# Note, we need to combine the variables into 1 data frame first:
y=cbind(starts, comps)
#y_ts=ts.union(starts, comps) # You can also use this function
y_tot=data.frame(y)
# To fit a VAR(p) model, simply call 'VAR' and set p=value
# Use var.select
y_model=VAR(y_tot,p=4)
summary(y_model)
# We interpret the coefficients in the usual way,but now have a
# system of equations. For example, for VAR(1) we have:
# y1 = c11 y(1,t-1) + c12 y(2,t-1)
# y2 = c21 y(1,t-1) + c22 y(2,t-1)
# The ourtput from summary are cij, cov, and corr.
# Plot the fit and orginal data
windows()
plot(y_model)
#pdf("varplot.pdf", width=8, height=8)
#plot(y_model)
#dev.off()
# Look at ACF and PACf
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,2])
pacf(residuals(y_model)[,2])
# or even better
windows()
tsdisplay(residuals(y_model)[,2],main ="Comps = starts(t-k) + comps(t-k)")
# Impulse Response Function
irf(y_model)
#pdf("irf.pdf", width=8, height=8)
windows()
plot(irf(y_model, n.ahead=36))
#dev.off()
#Forecast
#holdout_matrix = hold out data
#var.predict = predict(object=y_model, n.ahead=52, dumvar=holdout_matrix);
var.predict = predict(object=y_model, n.ahead=52)
windows()
plot(var.predict)
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
dev.off()
#Granger Test
#Does LA granger-cause Riverside?
grangertest(comps ~ starts, order = 8)
#Variance Decomposition (Forecast Error Variance Decomposition)
windows()
plot(fevd(y_model, n.ahead = 5))
#CUSUM Plot
windows()
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 05/10/2015A
# Comment(s): R code for fitting VAR models
# Data File(s): housecomp.dat
#***********************************************
# Variable Definitions
# U.S. monthly seasonally adjusred housing starts and completion
# from 1968.01-1996.06
# housecomp.dat[,2] = housing starts
# housecomp.dat[,3] = hoising completion
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ 144/Week 6")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library(TTR)
library(tis)
require("datasets")
require(graphics)
library(forecast)
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
library(strucchange)
#library(MSBVAR)
library(vars)
library(lmtest)
library(dlnm)
# Look at the data
data=read.table("housecomp.dat")
starts<-ts(data[,2],start=1968.1,freq=12)
comps<-ts(data[,3],start=1968.1,freq=12)
windows()
plot(starts)
nberShade()
lines(starts,ylab="Housing Starts and Completions")
lines(comps,col="blue")
legend("topright",legend=c("Starts","Completions"),text.col=c("black","blue"),bty="n")
# Look at the ACF, PACF, and CCF (cros-correlation function)
windows()
tsdisplay(starts,main="Housing Starts")
windows()
tsdisplay(comps,main="Housing Completions")
windows()
ccf(starts,comps,ylab="Cross-Correlation Function", main = "Starts and Completions CCF")
# Completions are maximally correlated with starts lagged by 6-12 months.
# Fit a VAR(p) model to the data
# Note, we need to combine the variables into 1 data frame first:
y=cbind(starts, comps)
#y_ts=ts.union(starts, comps) # You can also use this function
y_tot=data.frame(y)
# To fit a VAR(p) model, simply call 'VAR' and set p=value
# Use var.select
y_model=VAR(y_tot,p=4)
summary(y_model)
# We interpret the coefficients in the usual way,but now have a
# system of equations. For example, for VAR(1) we have:
# y1 = c11 y(1,t-1) + c12 y(2,t-1)
# y2 = c21 y(1,t-1) + c22 y(2,t-1)
# The ourtput from summary are cij, cov, and corr.
# Plot the fit and orginal data
windows()
plot(y_model)
#pdf("varplot.pdf", width=8, height=8)
#plot(y_model)
#dev.off()
# Look at ACF and PACf
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,2])
pacf(residuals(y_model)[,2])
# or even better
windows()
tsdisplay(residuals(y_model)[,2],main ="Comps = starts(t-k) + comps(t-k)")
# Impulse Response Function
irf(y_model)
#pdf("irf.pdf", width=8, height=8)
windows()
plot(irf(y_model, n.ahead=36))
#dev.off()
#Forecast
#holdout_matrix = hold out data
#var.predict = predict(object=y_model, n.ahead=52, dumvar=holdout_matrix);
var.predict = predict(object=y_model, n.ahead=52)
windows()
plot(var.predict)
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
dev.off()
#Granger Test
#Does LA granger-cause Riverside?
grangertest(comps ~ starts, order = 8)
#Variance Decomposition (Forecast Error Variance Decomposition)
windows()
plot(fevd(y_model, n.ahead = 5))
#CUSUM Plot
windows()
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
setwd("/Users/Xiang/OneDrive/Desktop/Econ 144/Week 6")
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ-144/Week 6")
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 05/10/2015A
# Comment(s): R code for fitting VAR models
# Data File(s): housecomp.dat
#***********************************************
# Variable Definitions
# U.S. monthly seasonally adjusred housing starts and completion
# from 1968.01-1996.06
# housecomp.dat[,2] = housing starts
# housecomp.dat[,3] = hoising completion
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ-144/Week 6")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library(TTR)
library(tis)
require("datasets")
require(graphics)
library(forecast)
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
library(strucchange)
#library(MSBVAR)
library(vars)
library(lmtest)
library(dlnm)
# Look at the data
data=read.table("housecomp.dat")
starts<-ts(data[,2],start=1968.1,freq=12)
comps<-ts(data[,3],start=1968.1,freq=12)
windows()
plot(starts)
nberShade()
lines(starts,ylab="Housing Starts and Completions")
lines(comps,col="blue")
legend("topright",legend=c("Starts","Completions"),text.col=c("black","blue"),bty="n")
# Look at the ACF, PACF, and CCF (cros-correlation function)
windows()
tsdisplay(starts,main="Housing Starts")
windows()
tsdisplay(comps,main="Housing Completions")
windows()
ccf(starts,comps,ylab="Cross-Correlation Function", main = "Starts and Completions CCF")
# Completions are maximally correlated with starts lagged by 6-12 months.
# Fit a VAR(p) model to the data
# Note, we need to combine the variables into 1 data frame first:
y=cbind(starts, comps)
#y_ts=ts.union(starts, comps) # You can also use this function
y_tot=data.frame(y)
# To fit a VAR(p) model, simply call 'VAR' and set p=value
# Use var.select
y_model=VAR(y_tot,p=4)
summary(y_model)
# We interpret the coefficients in the usual way,but now have a
# system of equations. For example, for VAR(1) we have:
# y1 = c11 y(1,t-1) + c12 y(2,t-1)
# y2 = c21 y(1,t-1) + c22 y(2,t-1)
# The ourtput from summary are cij, cov, and corr.
# Plot the fit and orginal data
windows()
plot(y_model)
#pdf("varplot.pdf", width=8, height=8)
#plot(y_model)
#dev.off()
# Look at ACF and PACf
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,2])
pacf(residuals(y_model)[,2])
# or even better
windows()
tsdisplay(residuals(y_model)[,2],main ="Comps = starts(t-k) + comps(t-k)")
# Impulse Response Function
irf(y_model)
#pdf("irf.pdf", width=8, height=8)
windows()
plot(irf(y_model, n.ahead=36))
#dev.off()
#Forecast
#holdout_matrix = hold out data
#var.predict = predict(object=y_model, n.ahead=52, dumvar=holdout_matrix);
var.predict = predict(object=y_model, n.ahead=52)
windows()
plot(var.predict)
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
dev.off()
#Granger Test
#Does LA granger-cause Riverside?
grangertest(comps ~ starts, order = 8)
#Variance Decomposition (Forecast Error Variance Decomposition)
windows()
plot(fevd(y_model, n.ahead = 5))
#CUSUM Plot
windows()
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
plot(y_model)
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])
tsdisplay(residuals(y_model)[,2],main ="Comps = starts(t-k) + comps(t-k)")
plot(irf(y_model, n.ahead=36))
plot(fevd(y_model, n.ahead = 5))
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
var.predict = predict(object=y_model, n.ahead=52)
windows()
plot(var.predict)
y_model
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
dev.off()
