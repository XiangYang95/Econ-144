plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(arma1$fitted.values,col="blue",lwd=2,lty=2)
lines(arma2$fitted.values,col="seagreen2",lwd=2,lty=2)
lines(arma3$fitted.values,col="red",lwd=2,lty=2)
legend("topright",legend=c("Data","ARMA(2,1)","ARMA(1,2)","ARMA(1,1)"),text.col=1:4,bty="n")
# Examine the best fit AR(p) model
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(arma3$fitted.values,col="red",lwd=1,lty=1)
plot(arma3$residuals,ylab="Residuals")
acf(arma3$residuals[3:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(arma3$residuals[3:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# Simulate AR(p), MA(q), and ARMA(p,q) process and test the theory :)
# 1. Simulate an MA(2) process. Accroding to theory, the ACF cuts-off at lag=2
ma.sim<-arima.sim(model=list(ma=c(-.7,.1)),n=1000) #Note: 'ma' has 2 coefficients, hence MA(2)
windows()
par(mfrow=(c(2,1)))
plot(ma.sim)
acf(ma.sim)
# 2. Simulate an AR(4) process. Accroding to theory, the PACF cuts-off at lag=4
ar.sim<-arima.sim(model=list(ar=c(.9,-.2,-.8,0.5)),n=10000) #Note: 'ar' has 2 coefficients, hence AR(4)
windows()
par(mfrow=c(2,1))
plot(ar.sim)
pacf(ar.sim)
# 2. Simulate an ARMA(2,2) process. According to theory,...??
#if the value for the ARMA are comparable, then it would be hard to identify because
#there are other dynamics that come in
arma.sim<-arima.sim(model=list(ar=c(.9,-.2),ma=c(-.7,.1)),n=10000)
windows()
par(mfrow=c(3,1))
plot(arma.sim)
acf(arma.sim)
pacf(arma.sim)
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 04/26/2015
# Comment(s): R fiting ARMA(p,q) models to data
# Data File(s): caemp.txt
#***********************************************
# Variable Definitions
# Canadian Employment Index (quarterly, seasonally adjusted starting from 1962)
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ-144/Week 5")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library("TTR")
library(tis)
require("datasets")
require(graphics)
library("forecast")
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
#NOTE: to add recession bands:
# Example: Presidents approval rating
#plot(presidents, type='n', ylab="Presidents approval rating")
#nberShade()
#lines(presidents)
# Read in the data into a ts data file:
caemp=read.table("caemp.txt")
caemp_ts<-ts(caemp,start=1962.1,freq=4)
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
# Look at the correlogram
windows()
par(mfrow=c(3,1))
acf(caemp_ts, type = "covariance", main="Autocovariance",lag.max=50, ylab="COV")
acf(caemp_ts, type = "correlation", main="Autocorrelation",lag.max=50,ylab="ACF")
acf(caemp_ts, type = "partial",main="Partial Autocorrelation",lag.max=50, ylab="PACF")
# The plots show evidence of serial corrleation --> cycles
# ACF plot: High during business cylce booms, and low during recessions.
# For further discussion read pages 130-132 of the textbook.
# Test the white noise Ho:
acf_val=acf(caemp_ts)$acf
Box.test(acf_val, type = "Ljung-Box")
Box.test(acf_val, type = "Box-Pierce")
#Sometimes low order ARMA is better that high order AR or MA
# MA(q) Model Fitting (see page 155)
ma1=arma(caemp_ts,order=c(0,1)) #Same as MA(1) = AR(0) + MA(1)
summary(ma1)
ma2=arma(caemp_ts,order=c(0,2)) #Same as MA(2) = AR(0) + MA(2)
summary(ma2)
ma3=arma(caemp_ts,order=c(0,10)) #Same as MA(10) = AR(0) + MA(10)
summary(ma3)
#plot(ma3)
# Look at all the MA(q) fits
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(ma1$fitted.values,col="blue",lwd=2)
lines(ma2$fitted.values,col="seagreen2",lwd=2)
lines(ma3$fitted.values,col="red",lwd=2)
legend("topright",legend=c("Data","MA(10)","MA(2)","MA(1)"),text.col=1:4,bty="n")
# Examine the best fit MA(q) model
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(ma3$fitted.values,col="red",lwd=1,lty=1)
plot(ma3$residuals,ylab="Residuals")
acf(ma3$residuals[12:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(ma3$residuals[12:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# Overall, even with the high q-order, the MA(q) model is not that good!
# AR(p) Model Fitting (see page 157)
ar1=ar(caemp_ts,FALSE,1) #Same as AR(1), FALSE is needed to allow for different values of p
ar1
ar2=ar(caemp_ts,FALSE,2) #Same as AR(2), Note: if no set FALSE, it will figure the best order (p)
ar2
ar3=ar(caemp_ts,FALSE,3) #Same as AR(3)
ar3
# You can also use ARMA(p,q) but setting q=0 this time.
ar1=arma(caemp_ts,order=c(1,0)) #Same as AR(1) = AR(1) + MA(0)
summary(ar1)
ar2=arma(caemp_ts,order=c(2,0)) #Same as AR(2) = AR(2) + MA(0)
summary(ar2)
ar3=arma(caemp_ts,order=c(3,0)) #Same as AR(3) = AR(3) + MA(0)
summary(ar3)
#plot(ar2)
# Look at all the AR(p) fits
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(ar1$fitted.values,col="blue",lwd=2,lty=2)
lines(ar2$fitted.values,col="seagreen2",lwd=2,lty=2)
lines(ar3$fitted.values,col="red",lwd=2,lty=2)
legend("topright",legend=c("Data","AR(3)","AR(2)","AR(1)"),text.col=1:4,bty="n")
# Examine the best fit AR(p) model
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(ar2$fitted.values,col="red",lwd=1,lty=1)
plot(ar2$residuals,ylab="Residuals")
acf(ar2$residuals[3:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(ar2$residuals[3:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# We can see a significant improvement e.g., from looking at the ACF and PACF plots, the
# residuals now look consistent with noise, suggesting we accounted for most (or all) of
# the dynamics left after detrending and seasonally adjusting the data.
# NOTE: With AR we only need p=2 unlike MA which required a much higher order polynomial.
# ARMA(p,q) Model Fitting (see page 157)
arma1=arma(caemp_ts,order=c(1,1)) # AR(1) + MA(1)
summary(arma1)
arma2=arma(caemp_ts,order=c(1,2)) # AR(1) + MA(2)
summary(arma2)
arma3=arma(caemp_ts,order=c(2,1)) # AR(2) + MA(1)
summary(arma3)
arma4=arma(caemp_ts,order=c(2,2)) # AR(2) + MA(2)
summary(arma4)
#plot(ar2)
# Look at all the ARMA(p,q) fits
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(arma1$fitted.values,col="blue",lwd=2,lty=2)
lines(arma2$fitted.values,col="seagreen2",lwd=2,lty=2)
lines(arma3$fitted.values,col="red",lwd=2,lty=2)
legend("topright",legend=c("Data","ARMA(2,1)","ARMA(1,2)","ARMA(1,1)"),text.col=1:4,bty="n")
# Examine the best fit AR(p) model
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(arma3$fitted.values,col="red",lwd=1,lty=1)
plot(arma3$residuals,ylab="Residuals")
acf(arma3$residuals[3:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(arma3$residuals[3:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# Simulate AR(p), MA(q), and ARMA(p,q) process and test the theory :)
# 1. Simulate an MA(2) process. Accroding to theory, the ACF cuts-off at lag=2
ma.sim<-arima.sim(model=list(ma=c(-.7,.1)),n=1000) #Note: 'ma' has 2 coefficients, hence MA(2)
windows()
par(mfrow=(c(2,1)))
plot(ma.sim)
acf(ma.sim)
# 2. Simulate an AR(4) process. Accroding to theory, the PACF cuts-off at lag=4
ar.sim<-arima.sim(model=list(ar=c(.9,-.2,-.8,0.5)),n=10000) #Note: 'ar' has 2 coefficients, hence AR(4)
windows()
par(mfrow=c(2,1))
plot(ar.sim)
pacf(ar.sim)
# 2. Simulate an ARMA(2,2) process. According to theory,...??
#if the value for the ARMA are comparable, then it would be hard to identify because
#there are other dynamics that come in
arma.sim<-arima.sim(model=list(ar=c(.9,-.2),ma=c(-.7,.1)),n=10000)
windows()
par(mfrow=c(3,1))
plot(arma.sim)
acf(arma.sim)
pacf(arma.sim)
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(ma1$fitted.values,col="blue",lwd=2)
lines(ma2$fitted.values,col="seagreen2",lwd=2)
lines(ma3$fitted.values,col="red",lwd=2)
legend("topright",legend=c("Data","MA(10)","MA(2)","MA(1)"),text.col=1:4,bty="n")
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(ma3$fitted.values,col="red",lwd=1,lty=1)
plot(ma3$residuals,ylab="Residuals")
acf(ma3$residuals[12:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(ma3$residuals[12:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# Overall, even with the high q-order, the MA(q) model is not that good!
ar1=ar(caemp_ts,FALSE,1) #Same as AR(1), FALSE is needed to allow for different values of p
ar1
ar2=ar(caemp_ts,FALSE,2) #Same as AR(2), Note: if no set FALSE, it will figure the best order (p)
ar2
ar3=ar(caemp_ts,FALSE,3) #Same as AR(3)
ar3
# You can also use ARMA(p,q) but setting q=0 this time.
ar1=arma(caemp_ts,order=c(1,0)) #Same as AR(1) = AR(1) + MA(0)
summary(ar1)
ar2=arma(caemp_ts,order=c(2,0)) #Same as AR(2) = AR(2) + MA(0)
summary(ar2)
ar3=arma(caemp_ts,order=c(3,0)) #Same as AR(3) = AR(3) + MA(0)
summary(ar3)
#plot(ar2)
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(ar1$fitted.values,col="blue",lwd=2,lty=2)
lines(ar2$fitted.values,col="seagreen2",lwd=2,lty=2)
lines(ar3$fitted.values,col="red",lwd=2,lty=2)
legend("topright",legend=c("Data","AR(3)","AR(2)","AR(1)"),text.col=1:4,bty="n")
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(ar2$fitted.values,col="red",lwd=1,lty=1)
plot(ar2$residuals,ylab="Residuals")
acf(ar2$residuals[3:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(ar2$residuals[3:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
# We can see a significant improvement e.g., from looking at the ACF and PACF plots, the
# residuals now look consistent with noise, suggesting we accounted for most (or all) of
# the dynamics left after detrending and seasonally adjusting the data.
# NOTE: With AR we only need p=2 unlike MA which required a much higher order polyno
arma1=arma(caemp_ts,order=c(1,1)) # AR(1) + MA(1)
summary(arma1)
arma2=arma(caemp_ts,order=c(1,2)) # AR(1) + MA(2)
summary(arma2)
arma3=arma(caemp_ts,order=c(2,1)) # AR(2) + MA(1)
summary(arma3)
arma4=arma(caemp_ts,order=c(2,2)) # AR(2) + MA(2)
summary(arma4)
#plot(ar2)
# Look at all the ARMA(p,q) fits
windows()
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
grid()
lines(arma1$fitted.values,col="blue",lwd=2,lty=2)
lines(arma2$fitted.values,col="seagreen2",lwd=2,lty=2)
lines(arma3$fitted.values,col="red",lwd=2,lty=2)
legend("topright",legend=c("Data","ARMA(2,1)","ARMA(1,2)","ARMA(1,1)"),text.col=1:4,bty="n")
windows()
par(mfrow=c(2,2))
plot(caemp_ts,xlab='Year', ylab="Canadian Employment", lwd=2)
lines(arma3$fitted.values,col="red",lwd=1,lty=1)
plot(arma3$residuals,ylab="Residuals")
acf(arma3$residuals[3:136], type = "correlation", main="Autocorrelation",lag.max=13,ylab="ACF")
acf(arma3$residuals[3:136], type = "partial",main="Partial Autocorrelation",lag.max=13, ylab="PACF")
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 05/10/2015A
# Comment(s): R code for fitting VAR models
# Data File(s): housecomp.dat
#***********************************************
# Variable Definitions
# U.S. monthly seasonally adjusred housing starts and completion
# from 1968.01-1996.06
# housecomp.dat[,2] = housing starts
# housecomp.dat[,3] = hoising completion
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ-144/Week 6")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library(TTR)
library(tis)
require("datasets")
require(graphics)
library(forecast)
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
library(strucchange)
#library(MSBVAR)
library(vars)
library(lmtest)
library(dlnm)
# Look at the data
data=read.table("housecomp.dat")
starts<-ts(data[,2],start=1968.1,freq=12)
comps<-ts(data[,3],start=1968.1,freq=12)
windows()
plot(starts)
nberShade()
lines(starts,ylab="Housing Starts and Completions")
lines(comps,col="blue")
legend("topright",legend=c("Starts","Completions"),text.col=c("black","blue"),bty="n")
# Look at the ACF, PACF, and CCF (cros-correlation function)
windows()
tsdisplay(starts,main="Housing Starts")
windows()
tsdisplay(comps,main="Housing Completions")
windows()
ccf(starts,comps,ylab="Cross-Correlation Function", main = "Starts and Completions CCF")
# Completions are maximally correlated with starts lagged by 6-12 months.
# Fit a VAR(p) model to the data
# Note, we need to combine the variables into 1 data frame first:
y=cbind(starts, comps)
#y_ts=ts.union(starts, comps) # You can also use this function
y_tot=data.frame(y)
# To fit a VAR(p) model, simply call 'VAR' and set p=value
# Use var.select
y_model=VAR(y_tot,p=4)
summary(y_model)
# We interpret the coefficients in the usual way,but now have a
# system of equations. For example, for VAR(1) we have:
# y1 = c11 y(1,t-1) + c12 y(2,t-1)
# y2 = c21 y(1,t-1) + c22 y(2,t-1)
# The ourtput from summary are cij, cov, and corr.
# Plot the fit and orginal data
windows()
plot(y_model)
#pdf("varplot.pdf", width=8, height=8)
#plot(y_model)
#dev.off()
# Look at ACF and PACf
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,1])
pacf(residuals(y_model)[,1])
windows()
par(mfrow=c(2,1))
acf(residuals(y_model)[,2])
pacf(residuals(y_model)[,2])
# or even better
windows()
tsdisplay(residuals(y_model)[,2],main ="Comps = starts(t-k) + comps(t-k)")
# Impulse Response Function
irf(y_model)
#pdf("irf.pdf", width=8, height=8)
windows()
#dev.off()
#Forecast
#holdout_matrix = hold out data
#var.predict = predict(object=y_model, n.ahead=52, dumvar=holdout_matrix);
var.predict = predict(object=y_model, n.ahead=52)
windows()
plot(var.predict)
dev.print(device=postscript,"forecast.eps",width=7,height=7, horizontal=FALSE)
dev.off()
#Granger Test
#Does LA granger-cause Riverside?
grangertest(comps ~ starts, order = 8)
#Variance Decomposition (Forecast Error Variance Decomposition)
windows()
plot(fevd(y_model, n.ahead = 5))
#CUSUM Plot
windows()
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
(y_model)[,1]
y_model[,1]
residuals(y_model)
plot(fevd(y_model, n.ahead = 5))
??fevd
windows()
plot(stability(y_model, type = "Rec-CUSUM"), plot.type="single")
irf(y_model)
plot(irf(y_model))
#***********************************************
# Randall R. Rojas
# Email: rrojas@econ.ucla.edu
# Date: 05/28/2015
# Comment(s): R code for fitting MAPA (Multiple Aggregation Prediction Algorithm) Model
# Data File(s): housecomp.dat
#***********************************************
# Variable Definitions
# Original Data are from: http://www.freddiemac.com/finance/fmhpi/archive.html
# MSA (1975-Current), MSA=Metropolitan State Area
# hpi.xls[,1] = Los Angles County -House Price Index
# hpi.xls[,2] = Riverside County -House Price Index
# We will be using a new library called 'MAPA'
#************************************************
# Set your 'working directory' to the folder where all the data and respective codes are located.
setwd("/Users/Xiang/OneDrive/Desktop/Econ-144/Week 7")
# Clear all variables and prior sessions
rm(list=ls(all=TRUE))
# Load Libraries
library(lattice)
library(foreign)
library(MASS)
library(car)
require(stats)
require(stats4)
library(KernSmooth)
library(fastICA)
library(cluster)
library(leaps)
library(mgcv)
library(rpart)
library(pan)
library(mgcv)
library(DAAG)
library(TTR)
library(tis)
require("datasets")
require(graphics)
library(forecast)
#install.packages("astsa")
#require(astsa)
library(xtable)
# New libraries added:
library(stats)
library(TSA)
library(timeSeries)
library(fUnitRoots)
library(fBasics)
library(tseries)
library(timsac)
library(TTR)
library(fpp)
library(strucchange)
#library(MSBVAR)
library(vars)
library(lmtest)
library(dlnm)
# Note: The library hts = Hierarchical Time Series can be used for forecast combination
library(hts)
library(MAPA)
set.seed(1)
library(openxlsx)
data = read.csv("hpi.csv", header = F)
LA_ts = ts(data$V1,start=1975,freq=12)
RI_ts = ts(data$V2,start=1975,freq=12)
# Detailed view of the data at each temporal aggregation level (daily, monthly, quarterly, annual)
# Note: paral = 2 --> Run in parallel cluster mode with e.g., in my case 4 cores
mapasimple(LA_ts,outplot=2,paral=2)
#Dynamic Fit to the data
mapafor(LA_ts,mapafit,ifh=12,fh=0)
# Best fit MAPA model by temporal decomposition + Forecast
# N=None, A=Additive, M=Multiplicative, d=Damped
# Exmaple: MAM = Holt-Winters
mapafit <- mapaest(LA_ts,paral=2)
mapafor(LA_ts,mapafit)
# Forecast with Error Bands
mapa(LA_ts,conf.lvl=c(0.8,0.9,0.95,0.99),paral=2)
mapasimple(LA_ts,outplot=2,paral=2)
mapafit <- mapaest(LA_ts,paral=2)
mapafor(LA_ts,mapafit)
mapafit
??ets
help(ets)
mapa(LA_ts,conf.lvl=c(0.8,0.9,0.95,0.99),paral=2)
View(data)
View(data)
help("ugarchspec")
